{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import gc\n",
    "from joblib import Parallel, delayed\n",
    "import random\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "from torch.utils.data import Subset\n",
    "import pickle as p\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from transformers import BertPreTrainedModel, BertModel\n",
    "from transformers.modeling_bert import BertOnlyMLMHead\n",
    "from torch import nn\n",
    "import sys\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams \n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords\n",
    "max_length = 200\n",
    "positive_label = [3]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LOTClassModel(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config, add_pooling_layer=False)\n",
    "        self.cls = BertOnlyMLMHead(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "        # MLM head is not trained\n",
    "        for param in self.cls.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, input_ids, pred_mode, attention_mask=None, token_type_ids=None, \n",
    "                position_ids=None, head_mask=None, inputs_embeds=None):\n",
    "        bert_outputs = self.bert(input_ids,\n",
    "                                 attention_mask=attention_mask,\n",
    "                                 token_type_ids=token_type_ids,\n",
    "                                 position_ids=position_ids,\n",
    "                                 head_mask=head_mask,\n",
    "                                 inputs_embeds=inputs_embeds)\n",
    "        last_hidden_states = bert_outputs[0]\n",
    "        if pred_mode == \"classification\":\n",
    "            trans_states = self.dense(last_hidden_states)\n",
    "            trans_states = self.activation(trans_states)\n",
    "            trans_states = self.dropout(trans_states)\n",
    "            logits = self.classifier(trans_states)\n",
    "        elif pred_mode == \"mlm\":\n",
    "            logits = self.cls(last_hidden_states)\n",
    "        else:\n",
    "            sys.exit(\"Wrong pred_mode!\")\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "vocab = tokenizer.get_vocab()\n",
    "inv_vocab = {k:v for v, k in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vocab = torch.load(\"category_vocab.pt\")\n",
    "label_data = torch.load(\"label_name_data.pt\")\n",
    "train_data = torch.load('train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('train.txt', encoding=\"utf-8\")\n",
    "true_labels = open('train_labels.txt', encoding=\"utf-8\")\n",
    "docs_labels = [doc.strip() for doc in true_labels.readlines()]\n",
    "dict_label = {0:[], 1:[], 2:[],3:[]}\n",
    "list_label = [int(label) for label in docs_labels]\n",
    "for i, label in enumerate(docs_labels):\n",
    "    if label in list(dict_label.keys()):\n",
    "        \n",
    "        dict_label[int(label)].append(i)\n",
    "    else:\n",
    "        dict_label[int(label)] = [i]\n",
    "docs = [doc.strip() for doc in corpus.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, number = 512, test_batch_size = 32,docs = docs, all = False, true_label = positive_label):\n",
    "    model.eval()\n",
    "    true_negative = 0\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    correct_pred = 0\n",
    "    negative = 0\n",
    "    divider = number\n",
    "    if all:\n",
    "        test_list = list(range(len(docs)))\n",
    "        divider = len(docs)\n",
    "    else:\n",
    "        test_list = random.sample(list(range(len(docs))), k = number)\n",
    "    inputs = torch.stack([encode(docs[i])[0].squeeze() for i in test_list])\n",
    "    attention_mask = torch.stack([encode(docs[i])[1].squeeze() for i in test_list])\n",
    "    true_labels = torch.stack([torch.tensor(int(list_label[i] in true_label)) for i in test_list])\n",
    "    test_dataset = TensorDataset(inputs, attention_mask, true_labels)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size = test_batch_size)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            inputs_test, attention_test, labels_test = batch\n",
    "            logits = model(inputs_test.to(device),attention_mask=attention_test.to(device), pred_mode='classification')\n",
    "            logits_cls = logits[:,0]\n",
    "            prediction = torch.argmax(logits_cls, -1)\n",
    "            \n",
    "            true_positive += (prediction.cpu()*labels_test).sum().item()\n",
    "            true_negative += ((1-prediction.cpu())*(1-labels_test)).sum().item()\n",
    "            false_positive += ((prediction.cpu())*(1-labels_test)).sum().item()\n",
    "            false_negative += ((1-prediction.cpu())*(labels_test)).sum().item()\n",
    "            correct_pred += (labels_test == prediction.cpu()).sum().item()\n",
    "            assert (correct_pred == (true_positive + true_negative))\n",
    "        assert(true_positive+true_negative+false_positive+false_negative == divider)\n",
    "        accuracy = correct_pred / divider\n",
    "        \n",
    "    if (true_positive+false_positive) > 0:\n",
    "        precision = true_positive / (true_positive+false_positive)\n",
    "        print('Precision', precision)\n",
    "    else : \n",
    "        precision = None\n",
    "        print(\"Precision Undefined\")\n",
    "    if (true_positive+false_negative) > 0 :\n",
    "        recall = true_positive/(true_positive+false_negative)\n",
    "        print('Recall', recall)\n",
    "    else :\n",
    "        recall = None\n",
    "        print(\"Recall Undefined\")\n",
    "    if recall is not None and precision is not None:\n",
    "        f1_score = 2*(recall*precision)/(recall+precision)\n",
    "        print(\"F1_score\", f1_score)\n",
    "    else:\n",
    "        print(\"F1_score Undefined\")\n",
    "    print(\"Accuracy \", accuracy)\n",
    "    model.train()\n",
    "    return accuracy\n",
    "        \n",
    "    \n",
    "    \n",
    "def encode(docs, tokenizer = tokenizer, max_length = max_length):\n",
    "    encoded_dict = tokenizer.encode_plus(docs, add_special_tokens=True, max_length=max_length, padding='max_length',\n",
    "                                                    return_attention_mask=True, truncation=True, return_tensors='pt')\n",
    "    input_ids = encoded_dict['input_ids']\n",
    "    attention_masks = encoded_dict['attention_mask']\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_vocab = []\n",
    "for k in data_vocab.keys():\n",
    "    category_vocab += list(data_vocab[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creer la liste de mots positifs\n",
    "list_pos_keyword = []\n",
    "for w in category_vocab:\n",
    "    list_pos_keyword.append(inv_vocab[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "negative_doc=[]\n",
    "negative_doc_label = []\n",
    "for k, doc in tqdm(enumerate(docs)):\n",
    "    tokenized_doc = tokenizer.tokenize(doc)\n",
    "    new_doc = []\n",
    "    wordpcs = []\n",
    "    label_idx = -1 * torch.ones(512, dtype=torch.long)\n",
    "    for idx, wordpc in enumerate(tokenized_doc):\n",
    "        wordpcs.append(wordpc[2:] if wordpc.startswith(\"##\") else wordpc)\n",
    "        if idx >= 512 - 1: # last index will be [SEP] token\n",
    "            break\n",
    "        if idx == len(doc) - 1 or not doc[idx+1].startswith(\"##\"):\n",
    "            word = ''.join(wordpcs)\n",
    "            if word in list_pos_keyword:\n",
    "                label_idx[idx] = 0\n",
    "                break\n",
    "            new_word = ''.join(wordpcs)\n",
    "            if new_word != tokenizer.unk_token:\n",
    "                idx += len(wordpcs)\n",
    "                new_doc.append(new_word)\n",
    "            wordpcs = []\n",
    "    if (label_idx>=0).any():\n",
    "        continue\n",
    "    else:\n",
    "        negative_doc_label.append(list_label[k])\n",
    "        negative_doc.append(doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Negative pre-set\", len(negative_doc))\n",
    "print(\"Precision pre-set, \", len([k for k in negative_doc_label if k not in positive_label])/len(negative_doc_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_list = []\n",
    "masks_list = []\n",
    "for doc in tqdm(negative_doc):\n",
    "    input_ids, input_mask = encode(doc)\n",
    "    inputs_list.append(input_ids)\n",
    "    masks_list.append(input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.stack(inputs_list).squeeze()\n",
    "mask_tensor = torch.stack(masks_list).squeeze()\n",
    "label_tensor = torch.stack([torch.tensor(i).unsqueeze(0) for i in negative_doc_label])\n",
    "dataset = torch.utils.data.TensorDataset(input_tensor,mask_tensor, label_tensor)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle = False, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_tensor(t1, t2, device = 'cuda', mask = None):    \n",
    "    indices = torch.zeros_like(t1, dtype = torch.uint8, device = device)\n",
    "    for elem in t2:\n",
    "        indices = indices | (t1 == elem) \n",
    "        indices = indices.to(bool)\n",
    "        \n",
    "    if mask is not None:\n",
    "        indices = indices * mask \n",
    "    intersection = t1[indices]  \n",
    "    return intersection, indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_similar_words(batch, category_vocab = category_vocab):\n",
    "    prediction= batch[0]\n",
    "    input_mask = batch[1]\n",
    "    masked_pred = prediction[:input_mask.sum().item(),:]\n",
    "    _ , words = torch.topk(masked_pred, 8, -1)\n",
    "    counter = 0\n",
    "    for word in words.squeeze():\n",
    "        counter += int(len(np.intersect1d(word.numpy(), category_vocab))>0)\n",
    "        intersect_time = time() - intersect_time_start\n",
    "        if counter > 0:\n",
    "            print('break')\n",
    "            return False\n",
    "            break\n",
    "    return True\n",
    "            \n",
    "def occurences(word, vocab = category_vocab):\n",
    "    return len(np.intersect1d(word.cpu().numpy(), vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #### Get negative set\n",
    "# from time import time\n",
    "# verified_negative = []\n",
    "# correct_label = 0\n",
    "# verbose = False\n",
    "# topk = 10\n",
    "# vocab = torch.tensor(category_vocab).to(device)\n",
    "# min_similar_words = 0\n",
    "# max_category_word = 0\n",
    "# num_cpus = 8\n",
    "# with torch.no_grad():\n",
    "#     for k, batch in tqdm(enumerate(dataloader)):\n",
    "\n",
    "#         input_ids, input_mask, label_id = batch\n",
    "#         predictions = model(input_ids.to(device),\n",
    "#                         pred_mode=\"mlm\",\n",
    "#                         token_type_ids=None, \n",
    "#                         attention_mask=input_mask.to(device))\n",
    "\n",
    "        \n",
    "        \n",
    "#     ########### GPU    \n",
    "# #         intersection, indices = intersect_tensor(torch.topk(predictions,topk,-1)[1],vocab, \n",
    "# #                                                 mask = input_mask.unsqueeze(2).repeat(1,1,topk).to(device))\n",
    "# #         counts_similar_word_per_word = indices.sum(-1) \n",
    "        \n",
    "# #         counts = (counts_similar_word_per_word>min_similar_words).sum(-1)\n",
    "# #         end_intersection_time = time()\n",
    "        \n",
    "# #         indices_count = torch.where(counts<=0)[0]\n",
    "# #         for j in indices_count:\n",
    "# #             i = j.item()\n",
    "\n",
    "#     ################## CPU ####################\"\"\n",
    "# #         counts = Parallel(n_jobs=num_cpus)(delayed(count_similar_words)(batch) for batch in zip(predictions.cpu(), input_mask))\n",
    "    \n",
    "    \n",
    "    \n",
    "#         for i, doc in enumerate(predictions.cpu()):\n",
    "#             masked_pred = doc[:input_mask[i].sum().item(),:]\n",
    "#             _ , words = torch.topk(masked_pred, topk, -1)\n",
    "#             counter = 0\n",
    "            \n",
    "# #             counts = Parallel(n_jobs=num_cpus)(delayed(occurences)(word) \n",
    "# #                                                    for word in words.squeeze())\n",
    "# #             counter += len(np.where(np.array(counts)>min_similar_words)[0])\n",
    "#             for word in words.squeeze():\n",
    "# #                 counter += int(len(intersect_tensor(word, vocab))>0)\n",
    "#                 counter += int(len(np.intersect1d(word.cpu().numpy(), category_vocab))>min_similar_words)\n",
    "#                 if counter > max_category_word:\n",
    "#                     break\n",
    "\n",
    "# #             j = i.item()\n",
    "# #         for i in np.where(np.array(counts))[0]:\n",
    "\n",
    "#             if counter <= max_category_word:             \n",
    "#                 verified_negative.append(k*4+i)\n",
    "#                 if label_id[i] not in positive_label:\n",
    "#                     correct_label += 1 \n",
    "             \n",
    "#         if k%100 == 0:\n",
    "#             if len(verified_negative)>0:\n",
    "#                 print('accuracy :', correct_label/len(verified_negative))\n",
    "#                 print('number of elements retrieved', len(verified_negative))\n",
    "# #         if verbose:\n",
    "# #             print('Prediction time', end_prediction_time-start_time) \n",
    "# # #             print('bascule cpu', start_loop-end_prediction_time)\n",
    "# #             print('Intersection time', end_intersection_time-end_prediction_time)\n",
    "# # #             print('topk time', topk_time-start_loop)\n",
    "# #             print('counting time', end_counting_time-end_intersection_time)\n",
    "# #         del predictions\n",
    "# #         gc.collect()\n",
    "# #         torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as p\n",
    "\n",
    "# p.dump(verified_negative, open('verified_negative_politics.p','wb'))\n",
    "# p.dump(dataloader, open('dataloader_politics.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### TRAINING PART ###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DATASET CONSTRUCTION ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(ids, tokenizer=tokenizer):\n",
    "    strings = tokenizer.batch_decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_verified_negative = p.load(open('verified_negative_politics.p','rb'))\n",
    "# new_dataloader = p.load(open('dataloader_politics.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_data = torch.load('athlete/mcp_train.pt')\n",
    "label = torch.LongTensor([1]).repeat(len(mcp_data['labels']))\n",
    "mcp_data['labels'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dataset = torch.utils.data.TensorDataset(mcp_data['input_ids'], mcp_data['attention_masks'], mcp_data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Statistiques des deux Sets ####\n",
    "# negative_dataset = Subset(new_dataloader.dataset, new_verified_negative)\n",
    "# positive_dataset = torch.utils.data.TensorDataset(mcp_data['input_ids'], mcp_data['attention_masks'], mcp_data['labels'])\n",
    "\n",
    "## TO DO ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STATISTICS ON CORPUS\n",
    "# corpus = open('train.txt', encoding=\"utf-8\")\n",
    "# stopwords_vocab = stopwords.words('english')\n",
    "# lines = corpus.readlines()\n",
    "# words = chain.from_iterable(line.lower().split() for line in lines)\n",
    "# count = Counter(word for word in words if word not in stopwords_vocab)\n",
    "# count.most_common(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-37fc852d834b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# negative_dataset = Subset(new_dataloader.dataset, new_verified_negative)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpositive_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcp_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcp_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_masks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcp_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnegative_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# negative_dataset = Subset(new_dataloader.dataset, new_verified_negative)\n",
    "positive_dataset = torch.utils.data.TensorDataset(mcp_data['input_ids'], mcp_data['attention_masks'], mcp_data['labels'])\n",
    "negative_dataset = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Start of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST without further refinement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.hstack((np.zeros(int(len(negative_dataset)), dtype=np.int32),\n",
    "                    np.ones(int(len(positive_dataset)), dtype=np.int32)))\n",
    "\n",
    "class_sample_count = np.array(\n",
    "    [len(np.where(target == t)[0]) for t in np.unique(target)])\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in target])\n",
    "\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weigth = samples_weight.double()\n",
    "target = torch.from_numpy(target).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = torch.stack([negative_data[0][:max_length] for negative_data in negative_dataset] + \n",
    "            [positive_data[0][:max_length] for positive_data in positive_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.stack([negative_data[1][:max_length] for negative_data in negative_dataset] + \n",
    "            [positive_data[1][:max_length] for positive_data in positive_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(data,mask, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING LOOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def onehot(indexes, N=None, ignore_index=None):\n",
    "    \"\"\"\n",
    "    Creates a one-representation of indexes with N possible entries\n",
    "    if N is not specified, it will suit the maximum index appearing.\n",
    "    indexes is a long-tensor of indexes\n",
    "    ignore_index will be zero in onehot representation\n",
    "    \"\"\"\n",
    "    if N is None:\n",
    "        N = indexes.max() + 1\n",
    "    sz = list(indexes.size())\n",
    "    output = indexes.new().byte().resize_(*sz, N).zero_()\n",
    "    output.scatter_(-1, indexes.unsqueeze(-1), 1)\n",
    "    if ignore_index is not None and ignore_index >= 0:\n",
    "        output.masked_fill_(indexes.eq(ignore_index).unsqueeze(-1), 0)\n",
    "    return output\n",
    "\n",
    "\n",
    "def _is_long(x):\n",
    "    if hasattr(x, 'data'):\n",
    "        x = x.data\n",
    "    return isinstance(x, torch.LongTensor) or isinstance(x, torch.cuda.LongTensor)\n",
    "\n",
    "def cross_entropy(inputs, target, weight=None, ignore_index=-100, reduction='mean',\n",
    "                  smooth_eps=None, smooth_dist=None, from_logits=True):\n",
    "    \"\"\"cross entropy loss, with support for target distributions and label smoothing https://arxiv.org/abs/1512.00567\"\"\"\n",
    "    smooth_eps = smooth_eps or 0\n",
    "\n",
    "    # ordinary log-liklihood - use cross_entropy from nn\n",
    "    if _is_long(target) and smooth_eps == 0:\n",
    "        if from_logits:\n",
    "            return F.cross_entropy(inputs, target, weight, ignore_index=ignore_index, reduction=reduction)\n",
    "        else:\n",
    "            return F.nll_loss(inputs, target, weight, ignore_index=ignore_index, reduction=reduction)\n",
    "\n",
    "    if from_logits:\n",
    "        # log-softmax of inputs\n",
    "        lsm = F.log_softmax(inputs, dim=-1)\n",
    "    else:\n",
    "        lsm = inputs\n",
    "\n",
    "    masked_indices = None\n",
    "    num_classes = inputs.size(-1)\n",
    "\n",
    "    if _is_long(target) and ignore_index >= 0:\n",
    "        masked_indices = target.eq(ignore_index)\n",
    "\n",
    "    if smooth_eps > 0 and smooth_dist is not None:\n",
    "        if _is_long(target):\n",
    "            target = onehot(target, num_classes).type_as(inputs)\n",
    "        if smooth_dist.dim() < target.dim():\n",
    "            smooth_dist = smooth_dist.unsqueeze(0)\n",
    "        target.lerp_(smooth_dist, smooth_eps)\n",
    "\n",
    "    if weight is not None:\n",
    "        lsm = lsm * weight.unsqueeze(0)\n",
    "\n",
    "    if _is_long(target):\n",
    "        eps_sum = smooth_eps / num_classes\n",
    "        eps_nll = 1. - eps_sum - smooth_eps\n",
    "        likelihood = lsm.gather(dim=-1, index=target.unsqueeze(-1)).squeeze(-1)\n",
    "        loss = -(eps_nll * likelihood + eps_sum * lsm.sum(-1))\n",
    "    else:\n",
    "        loss = -(target * lsm).sum(-1)\n",
    "\n",
    "    if masked_indices is not None:\n",
    "        loss.masked_fill_(masked_indices, 0)\n",
    "\n",
    "    if reduction == 'sum':\n",
    "        loss = loss.sum()\n",
    "    elif reduction == 'mean':\n",
    "        if masked_indices is None:\n",
    "            loss = loss.mean()\n",
    "        else:\n",
    "            loss = loss.sum() / float(loss.size(0) - masked_indices.sum())\n",
    "\n",
    "    return loss\n",
    "\n",
    "class CrossEntropyLoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"CrossEntropyLoss - with ability to recieve distrbution as targets, and optional label smoothing\"\"\"\n",
    "\n",
    "    def __init__(self, weight=None, ignore_index=-100, reduction='mean', smooth_eps=None, smooth_dist=None, from_logits=True):\n",
    "        super(CrossEntropyLoss, self).__init__(weight=weight,\n",
    "                                               ignore_index=ignore_index, reduction=reduction)\n",
    "        self.smooth_eps = smooth_eps\n",
    "        self.smooth_dist = smooth_dist\n",
    "        self.from_logits = from_logits\n",
    "\n",
    "    def forward(self, input, target, smooth_dist=None):\n",
    "        if smooth_dist is None:\n",
    "            smooth_dist = self.smooth_dist\n",
    "        return cross_entropy(input, target, weight=self.weight, ignore_index=self.ignore_index,\n",
    "                             reduction=self.reduction, smooth_eps=self.smooth_eps,\n",
    "                             smooth_dist=smooth_dist, from_logits=self.from_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LOTClassModel.from_pretrained('bert-base-uncased',\n",
    "                                           output_attentions=False,\n",
    "                                           output_hidden_states=False,\n",
    "                                           num_labels=2).to(device)\n",
    "accum_steps = 8\n",
    "model.train()\n",
    "epochs = 1\n",
    "smooth_eps = 1e-2\n",
    "train_loss = CrossEntropyLoss(smooth_eps=smooth_eps)\n",
    "total_steps = len(train_loader) * epochs / accum_steps\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*total_steps, num_training_steps=total_steps)\n",
    "losses_track = []\n",
    "try:\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        model.zero_grad()\n",
    "        for j, batch in enumerate(train_loader):\n",
    "            input_ids = batch[0].to(device)\n",
    "            input_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "\n",
    "\n",
    "            ### RANDOM MASKING\n",
    "            random_masking = random.choices(list(range(max_length-1)),k=batch_size)\n",
    "            for i, mask_pos in enumerate(random_masking):\n",
    "                input_ids[i,mask_pos+1] = tokenizer.get_vocab()[tokenizer.mask_token]\n",
    "            \n",
    "            ### PREDICTION\n",
    "            logits = model(input_ids, \n",
    "                           pred_mode=\"classification\",\n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=input_mask)\n",
    "            ### LOSS\n",
    "            logits_cls = logits[:,0]\n",
    "            loss = train_loss(logits_cls.view(-1, 2), labels.view(-1)) / accum_steps            \n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            if (j+1) % accum_steps == 0:\n",
    "                # Clip the norm of the gradients to 1.0.\n",
    "                losses_track.append(loss*accum_steps)\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.zero_grad()\n",
    "            if (j+1) % 5*accum_steps == 0 :\n",
    "                print(loss*accum_steps)\n",
    "                test(model)\n",
    "        avg_train_loss = torch.tensor([total_train_loss / len(train_loader) * accum_steps]).to(device)\n",
    "        print(f\"Average training loss: {avg_train_loss.mean().item()}\")\n",
    "\n",
    "except RuntimeError as err:\n",
    "    print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as p\n",
    "# p.dump(verified_negative, open('verified_negative.p','wb'))\n",
    "# p.dump(dataloader, open('dataloader.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## TRAINING #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model=model, all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = random.sample(range(120000), k=1)[0]\n",
    "x, m = encode(docs[k])\n",
    "label = list_label[k]\n",
    "pred = model(x.to(device), attention_mask = m.to(device), pred_mode='classification')\n",
    "print(torch.argmax(pred[0,0,:]))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "227.73*512/120000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top k = top 8 -> ~0.8 accuracy, 400 datapoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
