{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import gc\n",
    "from joblib import Parallel, delayed\n",
    "import random\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "from torch.utils.data import Subset\n",
    "import pickle as p\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from transformers import BertPreTrainedModel, BertModel\n",
    "from transformers.modeling_bert import BertOnlyMLMHead\n",
    "from torch import nn\n",
    "import sys\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams \n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "positive_label = [3]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LOTClassModel(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config, add_pooling_layer=False)\n",
    "        self.cls = BertOnlyMLMHead(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "        # MLM head is not trained\n",
    "        for param in self.cls.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, input_ids, pred_mode, attention_mask=None, token_type_ids=None, \n",
    "                position_ids=None, head_mask=None, inputs_embeds=None):\n",
    "        bert_outputs = self.bert(input_ids,\n",
    "                                 attention_mask=attention_mask,\n",
    "                                 token_type_ids=token_type_ids,\n",
    "                                 position_ids=position_ids,\n",
    "                                 head_mask=head_mask,\n",
    "                                 inputs_embeds=inputs_embeds)\n",
    "        last_hidden_states = bert_outputs[0]\n",
    "        if pred_mode == \"classification\":\n",
    "            trans_states = self.dense(last_hidden_states)\n",
    "            trans_states = self.activation(trans_states)\n",
    "            trans_states = self.dropout(trans_states)\n",
    "            logits = self.classifier(trans_states)\n",
    "        elif pred_mode == \"mlm\":\n",
    "            logits = self.cls(last_hidden_states)\n",
    "        else:\n",
    "            sys.exit(\"Wrong pred_mode!\")\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "vocab = tokenizer.get_vocab()\n",
    "inv_vocab = {k:v for v, k in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vocab = torch.load(\"category_vocab.pt\")\n",
    "label_data = torch.load(\"label_name_data.pt\")\n",
    "train_data = torch.load('train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('train.txt', encoding=\"utf-8\")\n",
    "true_labels = open('train_labels.txt', encoding=\"utf-8\")\n",
    "docs_labels = [doc.strip() for doc in true_labels.readlines()]\n",
    "dict_label = {0:[], 1:[], 2:[],3:[]}\n",
    "list_label = [int(label) for label in docs_labels]\n",
    "for i, label in enumerate(docs_labels):\n",
    "    if label in list(dict_label.keys()):\n",
    "        \n",
    "        dict_label[int(label)].append(i)\n",
    "    else:\n",
    "        dict_label[int(label)] = [i]\n",
    "docs = [doc.strip() for doc in corpus.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, number = 512, test_batch_size = 32,docs = docs, all = False, true_label = positive_label):\n",
    "    model.eval()\n",
    "    true_negative = 0\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    correct_pred = 0\n",
    "    negative = 0\n",
    "    divider = number\n",
    "    if all:\n",
    "        test_list = list(range(len(docs)))\n",
    "        divider = len(docs)\n",
    "    else:\n",
    "        test_list = random.sample(list(range(len(docs))), k = number)\n",
    "    inputs = torch.stack([encode(docs[i])[0].squeeze() for i in test_list])\n",
    "    attention_mask = torch.stack([encode(docs[i])[1].squeeze() for i in test_list])\n",
    "    true_labels = torch.stack([torch.tensor(int(list_label[i] in true_label)) for i in test_list])\n",
    "    test_dataset = TensorDataset(inputs, attention_mask, true_labels)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size = test_batch_size)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            inputs_test, attention_test, labels_test = batch\n",
    "            logits = model(inputs_test.to(device),attention_mask=attention_test.to(device), pred_mode='classification')\n",
    "            logits_cls = logits[:,0]\n",
    "            prediction = torch.argmax(logits_cls, -1)\n",
    "            \n",
    "            true_positive += ((labels_test == prediction.cpu())*torch.from_numpy(np.array([np.where(i in positive_label,1,0) for i in labels_test]))).sum().item()\n",
    "            true_negative += ((labels_test == prediction.cpu())*torch.from_numpy(np.array([np.where(i in positive_label,0,1) for i in labels_test]))).sum().item()\n",
    "            false_positive += ((labels_test != prediction.cpu())*torch.from_numpy(np.array([np.where(i in positive_label,1,0) for i in prediction.cpu()]))).sum().item()\n",
    "            false_negative += ((labels_test != prediction.cpu())*torch.from_numpy(np.array([np.where(i in positive_label,0,1) for i in prediction.cpu()]))).sum().item()\n",
    "            \n",
    "            \n",
    "            correct_pred += (labels_test == prediction.cpu()).sum().item()\n",
    "            assert (correct_pred == (true_positive + true_negative))\n",
    "        assert(true_positive+true_negative+false_positive+false_negative == divider)\n",
    "        accuracy = correct_pred / divider\n",
    "    if (true_positive+false_positive) > 0:\n",
    "        precision = true_positive / (true_positive+false_positive)\n",
    "        print('Precision', precision)\n",
    "    else : \n",
    "        precision = None\n",
    "        print(\"Precision Undefined\")\n",
    "    if (true_positive+false_negative) > 0 :\n",
    "        recall = true_positive/(true_positive+false_negative)\n",
    "        print('Recall', recall)\n",
    "    else :\n",
    "        recall = None\n",
    "        print(\"Recall Undefined\")\n",
    "    if recall is not None and precision is not None:\n",
    "        f1_score = 2*(recall*precison)/(recall+precision)\n",
    "        print(\"F1_score\", f1_score)\n",
    "    else:\n",
    "        print(\"F1_score Undefined\")\n",
    "    print(\"Accuracy \", accuracy)\n",
    "    model.train()\n",
    "    return accuracy\n",
    "        \n",
    "    \n",
    "    \n",
    "def encode(docs, tokenizer = tokenizer, max_length = 200):\n",
    "    encoded_dict = tokenizer.encode_plus(docs, add_special_tokens=True, max_length=max_length, padding='max_length',\n",
    "                                                    return_attention_mask=True, truncation=True, return_tensors='pt')\n",
    "    input_ids = encoded_dict['input_ids']\n",
    "    attention_masks = encoded_dict['attention_mask']\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1/16 [00:00<00:05,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 2/16 [00:00<00:05,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 3/16 [00:01<00:04,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 4/16 [00:01<00:04,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 5/16 [00:01<00:03,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 6/16 [00:01<00:03,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 7/16 [00:02<00:03,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 8/16 [00:02<00:02,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▋    | 9/16 [00:02<00:02,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 10/16 [00:03<00:01,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 11/16 [00:03<00:01,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 12/16 [00:03<00:01,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 13/16 [00:04<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 14/16 [00:04<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 15/16 [00:04<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "360\n",
      "Precision Undefined\n",
      "Recall 0.0\n",
      "F1_score Undefined\n",
      "Accuracy  0.703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.703125"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "where() received an invalid combination of arguments - got (bool, int, int), but expected one of:\n * (Tensor condition)\n * (Tensor condition, Tensor input, Tensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mbool\u001b[0m, \u001b[31;1mint\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (Tensor condition, Number self, Tensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mbool\u001b[0m, \u001b[31;1mint\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (Tensor condition, Tensor input, Number other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mbool\u001b[0m, \u001b[31;1mint\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (Tensor condition, Number self, Number other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mbool\u001b[0m, \u001b[31;1mint\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c2c47c2ea1c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositive_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-c2c47c2ea1c2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositive_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: where() received an invalid combination of arguments - got (bool, int, int), but expected one of:\n * (Tensor condition)\n * (Tensor condition, Tensor input, Tensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mbool\u001b[0m, \u001b[31;1mint\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (Tensor condition, Number self, Tensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mbool\u001b[0m, \u001b[31;1mint\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (Tensor condition, Tensor input, Number other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mbool\u001b[0m, \u001b[31;1mint\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (Tensor condition, Number self, Number other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mbool\u001b[0m, \u001b[31;1mint\u001b[0m, \u001b[31;1mint\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,0,2,3,5,8,4,1])\n",
    "[torch.where(i.item() in positive_label, 1,0) for i in torch.from_numpy(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_vocab = []\n",
    "for k in data_vocab.keys():\n",
    "    category_vocab += list(data_vocab[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creer la liste de mots positifs\n",
    "list_pos_keyword = []\n",
    "for w in category_vocab:\n",
    "    list_pos_keyword.append(inv_vocab[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5bfdcc797401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-45ad62bf90fe>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, number, test_batch_size, docs, all, true_label)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mlogits_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mtrue_positive\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositive_label\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mtrue_negative\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositive_label\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlables_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mcorrect_pred\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "560000it [06:00, 1554.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "negative_doc=[]\n",
    "negative_doc_label = []\n",
    "for k, doc in tqdm(enumerate(docs)):\n",
    "    tokenized_doc = tokenizer.tokenize(doc)\n",
    "    new_doc = []\n",
    "    wordpcs = []\n",
    "    label_idx = -1 * torch.ones(512, dtype=torch.long)\n",
    "    for idx, wordpc in enumerate(tokenized_doc):\n",
    "        wordpcs.append(wordpc[2:] if wordpc.startswith(\"##\") else wordpc)\n",
    "        if idx >= 512 - 1: # last index will be [SEP] token\n",
    "            break\n",
    "        if idx == len(doc) - 1 or not doc[idx+1].startswith(\"##\"):\n",
    "            word = ''.join(wordpcs)\n",
    "            if word in list_pos_keyword:\n",
    "                label_idx[idx] = 0\n",
    "                break\n",
    "            new_word = ''.join(wordpcs)\n",
    "            if new_word != tokenizer.unk_token:\n",
    "                idx += len(wordpcs)\n",
    "                new_doc.append(new_word)\n",
    "            wordpcs = []\n",
    "    if (label_idx>=0).any():\n",
    "        continue\n",
    "    else:\n",
    "        negative_doc_label.append(list_label[k])\n",
    "        negative_doc.append(doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative pre-set 277759\n",
      "Precision pre-set,  0.9844721503173615\n"
     ]
    }
   ],
   "source": [
    "print(\"Negative pre-set\", len(negative_doc))\n",
    "print(\"Precision pre-set, \", len([k for k in negative_doc_label if k not in positive_label])/len(negative_doc_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing LOTClassModel: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing LOTClassModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LOTClassModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LOTClassModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias', 'dense.weight', 'dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = LOTClassModel.from_pretrained('bert-base-uncased',\n",
    "                                           output_attentions=False,\n",
    "                                           output_hidden_states=False,\n",
    "                                           num_labels=2).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66370/66370 [00:38<00:00, 1706.85it/s]\n"
     ]
    }
   ],
   "source": [
    "inputs_list = []\n",
    "masks_list = []\n",
    "for doc in tqdm(negative_doc):\n",
    "    input_ids, input_mask = encode(doc)\n",
    "    inputs_list.append(input_ids)\n",
    "    masks_list.append(input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.stack(inputs_list).squeeze()\n",
    "mask_tensor = torch.stack(masks_list).squeeze()\n",
    "label_tensor = torch.stack([torch.tensor(i).unsqueeze(0) for i in negative_doc_label])\n",
    "dataset = torch.utils.data.TensorDataset(input_tensor,mask_tensor, label_tensor)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle = False, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_tensor(t1, t2, device = 'cuda', mask = None):    \n",
    "    indices = torch.zeros_like(t1, dtype = torch.uint8, device = device)\n",
    "    for elem in t2:\n",
    "        indices = indices | (t1 == elem) \n",
    "        indices = indices.to(bool)\n",
    "        \n",
    "    if mask is not None:\n",
    "        indices = indices * mask \n",
    "    intersection = t1[indices]  \n",
    "    return intersection, indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_similar_words(batch, category_vocab = category_vocab):\n",
    "    prediction= batch[0]\n",
    "    input_mask = batch[1]\n",
    "    masked_pred = prediction[:input_mask.sum().item(),:]\n",
    "    _ , words = torch.topk(masked_pred, 8, -1)\n",
    "    counter = 0\n",
    "    for word in words.squeeze():\n",
    "        counter += int(len(np.intersect1d(word.numpy(), category_vocab))>0)\n",
    "        intersect_time = time() - intersect_time_start\n",
    "        if counter > 0:\n",
    "            print('break')\n",
    "            return False\n",
    "            break\n",
    "    return True\n",
    "            \n",
    "def occurences(word, vocab = category_vocab):\n",
    "    return len(np.intersect1d(word.cpu().numpy(), vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:17,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8870967741935484\n",
      "number of elements retrieved 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "202it [00:34,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8888888888888888\n",
      "number of elements retrieved 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "302it [00:51,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8881987577639752\n",
      "number of elements retrieved 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "402it [01:08,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8979591836734694\n",
      "number of elements retrieved 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "502it [01:25,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9051383399209486\n",
      "number of elements retrieved 253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "602it [01:42,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9042904290429042\n",
      "number of elements retrieved 303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "702it [01:59,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8976608187134503\n",
      "number of elements retrieved 342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "802it [02:16,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8981233243967829\n",
      "number of elements retrieved 373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "902it [02:33,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.894484412470024\n",
      "number of elements retrieved 417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1002it [02:50,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.886021505376344\n",
      "number of elements retrieved 465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1102it [03:07,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8843813387423936\n",
      "number of elements retrieved 493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1202it [03:24,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8886756238003839\n",
      "number of elements retrieved 521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1302it [03:41,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8914185639229422\n",
      "number of elements retrieved 571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1402it [03:58,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8903436988543372\n",
      "number of elements retrieved 611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1502it [04:15,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8893939393939394\n",
      "number of elements retrieved 660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1602it [04:33,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8866571018651362\n",
      "number of elements retrieved 697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1702it [04:50,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8763297872340425\n",
      "number of elements retrieved 752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1802it [05:08,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8735919899874843\n",
      "number of elements retrieved 799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1902it [05:25,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8656361474435196\n",
      "number of elements retrieved 841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2002it [05:43,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8693693693693694\n",
      "number of elements retrieved 888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2102it [06:00,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8751334044823906\n",
      "number of elements retrieved 937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2202it [06:18,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8752556237218814\n",
      "number of elements retrieved 978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2302it [06:35,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8725490196078431\n",
      "number of elements retrieved 1020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2402it [06:52,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8726591760299626\n",
      "number of elements retrieved 1068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2502it [07:10,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8710550045085663\n",
      "number of elements retrieved 1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2602it [07:27,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8729184925503944\n",
      "number of elements retrieved 1141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2702it [07:44,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8761506276150628\n",
      "number of elements retrieved 1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2802it [08:02,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8769230769230769\n",
      "number of elements retrieved 1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2902it [08:19,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8778565799842396\n",
      "number of elements retrieved 1269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3002it [08:36,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.878234398782344\n",
      "number of elements retrieved 1314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3102it [08:54,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8780308596620132\n",
      "number of elements retrieved 1361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3202it [09:11,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8767908309455588\n",
      "number of elements retrieved 1396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3302it [09:29,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8782365290412876\n",
      "number of elements retrieved 1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3402it [09:46,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8778371161548731\n",
      "number of elements retrieved 1498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3502it [10:03,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8764705882352941\n",
      "number of elements retrieved 1530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3602it [10:20,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8779402415766052\n",
      "number of elements retrieved 1573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3702it [10:37,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8788819875776398\n",
      "number of elements retrieved 1610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3802it [10:54,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.876357056694813\n",
      "number of elements retrieved 1658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3902it [11:11,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8763250883392226\n",
      "number of elements retrieved 1698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4002it [11:28,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8752146536920435\n",
      "number of elements retrieved 1747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4102it [11:45,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8748603351955307\n",
      "number of elements retrieved 1790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4202it [12:02,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8767567567567568\n",
      "number of elements retrieved 1850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4302it [12:19,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.877906976744186\n",
      "number of elements retrieved 1892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4402it [12:36,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8767967145790554\n",
      "number of elements retrieved 1948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4502it [12:53,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8761952692501258\n",
      "number of elements retrieved 1987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4602it [13:10,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8743196437407225\n",
      "number of elements retrieved 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4702it [13:27,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8748187530207829\n",
      "number of elements retrieved 2069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4802it [13:44,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8751182592242195\n",
      "number of elements retrieved 2114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4902it [14:01,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8730964467005076\n",
      "number of elements retrieved 2167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5002it [14:18,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8712291760468257\n",
      "number of elements retrieved 2221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5102it [14:35,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.870509977827051\n",
      "number of elements retrieved 2255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5202it [14:52,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8709677419354839\n",
      "number of elements retrieved 2294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5302it [15:09,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8725573491928632\n",
      "number of elements retrieved 2354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5402it [15:26,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8736447039199333\n",
      "number of elements retrieved 2398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5502it [15:43,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8765281173594132\n",
      "number of elements retrieved 2454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5602it [16:00,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8777064955894146\n",
      "number of elements retrieved 2494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5702it [16:17,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8800157356412274\n",
      "number of elements retrieved 2542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5802it [16:34,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8803716608594657\n",
      "number of elements retrieved 2583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5902it [16:51,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8806883365200765\n",
      "number of elements retrieved 2615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6002it [17:08,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8807097017742544\n",
      "number of elements retrieved 2649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6102it [17:25,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8823311061618412\n",
      "number of elements retrieved 2694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6202it [17:42,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8808309037900874\n",
      "number of elements retrieved 2744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6302it [17:59,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8813803019410497\n",
      "number of elements retrieved 2782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6402it [18:16,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8813257305773343\n",
      "number of elements retrieved 2806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6502it [18:33,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8823322795925536\n",
      "number of elements retrieved 2847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6602it [18:50,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8826177285318559\n",
      "number of elements retrieved 2888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6702it [19:07,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.883617747440273\n",
      "number of elements retrieved 2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6802it [19:23,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8836032388663968\n",
      "number of elements retrieved 2964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6902it [19:40,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8844370860927152\n",
      "number of elements retrieved 3020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7002it [19:57,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8846028113762667\n",
      "number of elements retrieved 3059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7102it [20:14,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8848758465011287\n",
      "number of elements retrieved 3101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7202it [20:31,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8842607313195548\n",
      "number of elements retrieved 3145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7302it [20:48,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8842897460018815\n",
      "number of elements retrieved 3189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7402it [21:05,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8841028819336846\n",
      "number of elements retrieved 3227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7502it [21:22,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8850398528510116\n",
      "number of elements retrieved 3262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7602it [21:39,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8848374354299605\n",
      "number of elements retrieved 3291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7702it [21:56,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8852606351108449\n",
      "number of elements retrieved 3338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7802it [22:13,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8854939187184812\n",
      "number of elements retrieved 3371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7902it [22:30,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8845029239766082\n",
      "number of elements retrieved 3420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8002it [22:47,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8849608809040858\n",
      "number of elements retrieved 3451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8102it [23:04,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8844827586206897\n",
      "number of elements retrieved 3480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8202it [23:21,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8844950213371267\n",
      "number of elements retrieved 3515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8297it [23:37,  5.85it/s]\n"
     ]
    }
   ],
   "source": [
    "#### Get negative set\n",
    "from time import time\n",
    "verified_negative = []\n",
    "correct_label = 0\n",
    "verbose = False\n",
    "topk = 10\n",
    "vocab = torch.tensor(category_vocab).to(device)\n",
    "min_similar_words = 0\n",
    "max_category_word = 0\n",
    "num_cpus = 8\n",
    "with torch.no_grad():\n",
    "    for k, batch in tqdm(enumerate(dataloader)):\n",
    "\n",
    "        input_ids, input_mask, label_id = batch\n",
    "        predictions = model(input_ids.to(device),\n",
    "                        pred_mode=\"mlm\",\n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=input_mask.to(device))\n",
    "\n",
    "        \n",
    "        \n",
    "    ########### GPU    \n",
    "#         intersection, indices = intersect_tensor(torch.topk(predictions,topk,-1)[1],vocab, \n",
    "#                                                 mask = input_mask.unsqueeze(2).repeat(1,1,topk).to(device))\n",
    "#         counts_similar_word_per_word = indices.sum(-1) \n",
    "        \n",
    "#         counts = (counts_similar_word_per_word>min_similar_words).sum(-1)\n",
    "#         end_intersection_time = time()\n",
    "        \n",
    "#         indices_count = torch.where(counts<=0)[0]\n",
    "#         for j in indices_count:\n",
    "#             i = j.item()\n",
    "\n",
    "    ################## CPU ####################\"\"\n",
    "#         counts = Parallel(n_jobs=num_cpus)(delayed(count_similar_words)(batch) for batch in zip(predictions.cpu(), input_mask))\n",
    "    \n",
    "    \n",
    "    \n",
    "        for i, doc in enumerate(predictions.cpu()):\n",
    "            masked_pred = doc[:input_mask[i].sum().item(),:]\n",
    "            _ , words = torch.topk(masked_pred, topk, -1)\n",
    "            counter = 0\n",
    "            \n",
    "#             counts = Parallel(n_jobs=num_cpus)(delayed(occurences)(word) \n",
    "#                                                    for word in words.squeeze())\n",
    "#             counter += len(np.where(np.array(counts)>min_similar_words)[0])\n",
    "            for word in words.squeeze():\n",
    "#                 counter += int(len(intersect_tensor(word, vocab))>0)\n",
    "                counter += int(len(np.intersect1d(word.cpu().numpy(), category_vocab))>min_similar_words)\n",
    "                if counter > max_category_word:\n",
    "                    break\n",
    "\n",
    "#             j = i.item()\n",
    "#         for i in np.where(np.array(counts))[0]:\n",
    "\n",
    "            if counter <= max_category_word:             \n",
    "                verified_negative.append(k*4+i)\n",
    "                if label_id[i] not in positive_label:\n",
    "                    correct_label += 1 \n",
    "             \n",
    "        if k%100 == 0:\n",
    "            if len(verified_negative)>0:\n",
    "                print('accuracy :', correct_label/len(verified_negative))\n",
    "                print('number of elements retrieved', len(verified_negative))\n",
    "#         if verbose:\n",
    "#             print('Prediction time', end_prediction_time-start_time) \n",
    "# #             print('bascule cpu', start_loop-end_prediction_time)\n",
    "#             print('Intersection time', end_intersection_time-end_prediction_time)\n",
    "# #             print('topk time', topk_time-start_loop)\n",
    "#             print('counting time', end_counting_time-end_intersection_time)\n",
    "#         del predictions\n",
    "#         gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as p\n",
    "\n",
    "p.dump(verified_negative, open('verified_negative_politics.p','wb'))\n",
    "p.dump(dataloader, open('dataloader_politics.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### TRAINING PART ###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DATASET CONSTRUCTION ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(ids, tokenizer=tokenizer):\n",
    "    strings = tokenizer.batch_decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_verified_negative = p.load(open('verified_negative_politics.p','rb'))\n",
    "new_dataloader = p.load(open('dataloader_politics.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_data = torch.load('mcp_train.pt')\n",
    "label = torch.LongTensor([1]).repeat(len(mcp_data['labels']))\n",
    "mcp_data['labels'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Statistiques des deux Sets ####\n",
    "negative_dataset = Subset(new_dataloader.dataset, new_verified_negative)\n",
    "positive_dataset = torch.utils.data.TensorDataset(mcp_data['input_ids'], mcp_data['attention_masks'], mcp_data['labels'])\n",
    "\n",
    "## TO DO ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STATISTICS ON CORPUS\n",
    "corpus = open('train.txt', encoding=\"utf-8\")\n",
    "stopwords_vocab = stopwords.words('english')\n",
    "lines = corpus.readlines()\n",
    "words = chain.from_iterable(line.lower().split() for line in lines)\n",
    "count = Counter(word for word in words if word not in stopwords_vocab)\n",
    "count.most_common(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_dataset = Subset(new_dataloader.dataset, new_verified_negative)\n",
    "positive_dataset = torch.utils.data.TensorDataset(mcp_data['input_ids'], mcp_data['attention_masks'], mcp_data['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Start of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.hstack((np.zeros(int(len(negative_dataset)), dtype=np.int32),\n",
    "                    np.ones(int(len(positive_dataset)), dtype=np.int32)))\n",
    "\n",
    "class_sample_count = np.array(\n",
    "    [len(np.where(target == t)[0]) for t in np.unique(target)])\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in target])\n",
    "\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weigth = samples_weight.double()\n",
    "target = torch.from_numpy(target).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.stack([negative_data[0][:200] for negative_data in negative_dataset] + \n",
    "            [positive_data[0][:200] for positive_data in positive_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.stack([negative_data[1][:200] for negative_data in negative_dataset] + \n",
    "            [positive_data[1][:200] for positive_data in positive_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(data,mask, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING LOOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing LOTClassModel: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing LOTClassModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LOTClassModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LOTClassModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias', 'dense.weight', 'dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 16/16 [00:05<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.640625\n",
      "tensor(0.7087, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.703125\n",
      "tensor(0.6882, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.619140625\n",
      "tensor(0.6369, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.6484375\n",
      "tensor(0.6561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6796, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.6328125\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.658203125\n",
      "tensor(0.6421, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.669921875\n",
      "tensor(0.6525, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.666015625\n",
      "tensor(0.6039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6513, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.744140625\n",
      "tensor(0.5866, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.75390625\n",
      "tensor(0.5831, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.7890625\n",
      "tensor(0.5620, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.779296875\n",
      "tensor(0.5717, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5439, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.80859375\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.841796875\n",
      "tensor(0.5708, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.822265625\n",
      "tensor(0.5623, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.8359375\n",
      "tensor(0.5491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5320, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.798828125\n",
      "tensor(0.5086, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.81640625\n",
      "tensor(0.5521, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.828125\n",
      "tensor(0.4803, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.83984375\n",
      "tensor(0.4790, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4496, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.830078125\n",
      "tensor(0.4735, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.841796875\n",
      "tensor(0.4460, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.81640625\n",
      "tensor(0.4971, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.861328125\n",
      "tensor(0.4522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4925, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.859375\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 15 is out of bounds for dimension 0 with size 15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-80580c37d4f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mrandom_masking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m199\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_pos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_masking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_pos\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m### PREDICTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 15 is out of bounds for dimension 0 with size 15"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LOTClassModel.from_pretrained('bert-base-uncased',\n",
    "                                           output_attentions=False,\n",
    "                                           output_hidden_states=False,\n",
    "                                           num_labels=2).to(device)\n",
    "accum_steps = 8\n",
    "model.train()\n",
    "epochs = 1\n",
    "train_loss = nn.CrossEntropyLoss()\n",
    "total_steps = len(train_loader) * epochs / accum_steps\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*total_steps, num_training_steps=total_steps)\n",
    "losses_track = []\n",
    "try:\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        model.zero_grad()\n",
    "        for j, batch in enumerate(train_loader):\n",
    "            input_ids = batch[0].to(device)\n",
    "            input_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "\n",
    "\n",
    "            ### RANDOM MASKING\n",
    "            random_masking = random.choices(list(range(199)),k=batch_size)\n",
    "            for i, mask_pos in enumerate(random_masking):\n",
    "                input_ids[i,mask_pos+1] = tokenizer.get_vocab()[tokenizer.mask_token]\n",
    "            \n",
    "            ### PREDICTION\n",
    "            logits = model(input_ids, \n",
    "                           pred_mode=\"classification\",\n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=input_mask)\n",
    "            ### LOSS\n",
    "            logits_cls = logits[:,0]\n",
    "            loss = train_loss(logits_cls.view(-1, 2), labels.view(-1)) / accum_steps            \n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            if (j+1) % accum_steps == 0:\n",
    "                # Clip the norm of the gradients to 1.0.\n",
    "                print(loss*accum_steps)\n",
    "                losses_track.append(loss*accum_steps)\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.zero_grad()\n",
    "            if j % 10 == 0 :\n",
    "                test(model)\n",
    "        avg_train_loss = torch.tensor([total_train_loss / len(train_loader) * accum_steps]).to(device)\n",
    "        print(f\"Average training loss: {avg_train_loss.mean().item()}\")\n",
    "\n",
    "except RuntimeError as err:\n",
    "    print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as p\n",
    "# p.dump(verified_negative, open('verified_negative.p','wb'))\n",
    "# p.dump(dataloader, open('dataloader.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## TRAINING #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [20:06<00:00,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.8578916666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8578916666666667"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model=model, all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0')\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "k = random.sample(range(120000), k=1)[0]\n",
    "x, m = encode(docs[k])\n",
    "label = list_label[k]\n",
    "pred = model(x.to(device), attention_mask = m.to(device), pred_mode='classification')\n",
    "print(torch.argmax(pred[0,0,:]))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.971648"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "227.73*512/120000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0')\n",
      "2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top k = top 8 -> ~0.8 accuracy, 400 datapoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
