{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import gc\n",
    "from joblib import Parallel, delayed\n",
    "import random\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "from torch.utils.data import Subset\n",
    "import pickle as p\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "positive_label = [0,2,3]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "vocab = tokenizer.get_vocab()\n",
    "inv_vocab = {k:v for v, k in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vocab = torch.load(\"category_vocab.pt\")\n",
    "label_data = torch.load(\"label_name_data.pt\")\n",
    "train_data = torch.load('train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('train.txt', encoding=\"utf-8\")\n",
    "true_labels = open('train_labels.txt', encoding=\"utf-8\")\n",
    "docs_labels = [doc.strip() for doc in true_labels.readlines()]\n",
    "dict_label = {0:[], 1:[], 2:[],3:[]}\n",
    "list_label = [int(label) for label in docs_labels]\n",
    "for i, label in enumerate(docs_labels):\n",
    "    dict_label[int(label)].append(i)\n",
    "docs = [doc.strip() for doc in corpus.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(number = 512, test_batch_size = 32,docs = docs, model=model, all = False, true_label = 1):\n",
    "    model.eval()\n",
    "    correct_pred = 0\n",
    "    if all:\n",
    "        test_list = list(range(len(docs)))\n",
    "    else:\n",
    "        test_list = random.sample(list(range(len(docs))), k = number)\n",
    "    inputs = torch.stack([encode(docs[i])[0].squeeze() for i in test_list])\n",
    "    attention_mask = torch.stack([encode(docs[i])[1].squeeze() for i in test_list])\n",
    "    true_labels = torch.stack([torch.tensor(int(list_label[i]==true_label)) for i in test_list])\n",
    "    test_dataset = TensorDataset(inputs, attention_mask, true_labels)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size = test_batch_size)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            inputs_test, attention_test, labels_test = batch\n",
    "            logits = model(inputs_test.to(device),attention_mask=attention_test.to(device), pred_mode='classification')\n",
    "            logits_cls = logits[:,0]\n",
    "            prediction = torch.argmax(logits_cls, -1)\n",
    "            correct_pred += (labels_test == prediction.cpu()).sum().item()\n",
    "        accuracy = correct_pred / number\n",
    "    print(\"Accuracy \", accuracy)\n",
    "    model.train()\n",
    "    return accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_vocab = []\n",
    "for k in data_vocab.keys():\n",
    "    category_vocab += list(data_vocab[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creer la liste de mots positifs\n",
    "list_pos_keyword = []\n",
    "for w in category_vocab:\n",
    "    list_pos_keyword.append(inv_vocab[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120000it [01:04, 1848.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "negative_doc=[]\n",
    "negative_doc_label = []\n",
    "for k, doc in tqdm(enumerate(docs)):\n",
    "    tokenized_doc = tokenizer.tokenize(doc)\n",
    "    new_doc = []\n",
    "    wordpcs = []\n",
    "    label_idx = -1 * torch.ones(512, dtype=torch.long)\n",
    "    for idx, wordpc in enumerate(tokenized_doc):\n",
    "        wordpcs.append(wordpc[2:] if wordpc.startswith(\"##\") else wordpc)\n",
    "        if idx >= 512 - 1: # last index will be [SEP] token\n",
    "            break\n",
    "        if idx == len(doc) - 1 or not doc[idx+1].startswith(\"##\"):\n",
    "            word = ''.join(wordpcs)\n",
    "            if word in list_pos_keyword:\n",
    "                label_idx[idx] = 0\n",
    "                break\n",
    "                # replace label names that are not in tokenizer's vocabulary with the [MASK] token\n",
    "    #             if word not in vocab:\n",
    "    #                 wordpcs = [tokenizer.mask_token]\n",
    "            new_word = ''.join(wordpcs)\n",
    "            if new_word != tokenizer.unk_token:\n",
    "                idx += len(wordpcs)\n",
    "                new_doc.append(new_word)\n",
    "            wordpcs = []\n",
    "    if (label_idx>=0).any():\n",
    "        continue\n",
    "    else:\n",
    "        negative_doc_label.append(list_label[k])\n",
    "        negative_doc.append(doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative pre-set 29892\n",
      "Accuracy pre-set,  0.4458718051652616\n"
     ]
    }
   ],
   "source": [
    "print(\"Negative pre-set\", len(negative_doc))\n",
    "print(\"Accuracy pre-set, \", len([k for k in negative_doc_label if k not in positive_label])/len(negative_doc_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing LOTClassModel: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing LOTClassModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LOTClassModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LOTClassModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias', 'dense.weight', 'dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertPreTrainedModel, BertModel\n",
    "from transformers.modeling_bert import BertOnlyMLMHead\n",
    "from torch import nn\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "def encode(docs, tokenizer = tokenizer):\n",
    "    encoded_dict = tokenizer.encode_plus(docs, add_special_tokens=True, max_length=200, padding='max_length',\n",
    "                                                    return_attention_mask=True, truncation=True, return_tensors='pt')\n",
    "    input_ids = encoded_dict['input_ids']\n",
    "    attention_masks = encoded_dict['attention_mask']\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "\n",
    "class LOTClassModel(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config, add_pooling_layer=False)\n",
    "        self.cls = BertOnlyMLMHead(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "        # MLM head is not trained\n",
    "        for param in self.cls.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, input_ids, pred_mode, attention_mask=None, token_type_ids=None, \n",
    "                position_ids=None, head_mask=None, inputs_embeds=None):\n",
    "        bert_outputs = self.bert(input_ids,\n",
    "                                 attention_mask=attention_mask,\n",
    "                                 token_type_ids=token_type_ids,\n",
    "                                 position_ids=position_ids,\n",
    "                                 head_mask=head_mask,\n",
    "                                 inputs_embeds=inputs_embeds)\n",
    "        last_hidden_states = bert_outputs[0]\n",
    "        if pred_mode == \"classification\":\n",
    "            trans_states = self.dense(last_hidden_states)\n",
    "            trans_states = self.activation(trans_states)\n",
    "            trans_states = self.dropout(trans_states)\n",
    "            logits = self.classifier(trans_states)\n",
    "        elif pred_mode == \"mlm\":\n",
    "            logits = self.cls(last_hidden_states)\n",
    "        else:\n",
    "            sys.exit(\"Wrong pred_mode!\")\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "model = LOTClassModel.from_pretrained('bert-base-uncased',\n",
    "                                           output_attentions=False,\n",
    "                                           output_hidden_states=False,\n",
    "                                           num_labels=2).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29892/29892 [00:16<00:00, 1858.49it/s]\n"
     ]
    }
   ],
   "source": [
    "inputs_list = []\n",
    "masks_list = []\n",
    "for doc in tqdm(negative_doc):\n",
    "    input_ids, input_mask = encode(doc)\n",
    "    inputs_list.append(input_ids)\n",
    "    masks_list.append(input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.stack(inputs_list).squeeze()\n",
    "mask_tensor = torch.stack(masks_list).squeeze()\n",
    "label_tensor = torch.stack([torch.tensor(i).unsqueeze(0) for i in negative_doc_label])\n",
    "dataset = torch.utils.data.TensorDataset(input_tensor,mask_tensor, label_tensor)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle = False, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_tensor(t1, t2, device = 'cuda', mask = None):    \n",
    "    indices = torch.zeros_like(t1, dtype = torch.uint8, device = device)\n",
    "    for elem in t2:\n",
    "        indices = indices | (t1 == elem) \n",
    "        indices = indices.to(bool)\n",
    "        \n",
    "    if mask is not None:\n",
    "        indices = indices * mask \n",
    "    intersection = t1[indices]  \n",
    "    return intersection, indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_similar_words(batch, category_vocab = category_vocab):\n",
    "    prediction= batch[0]\n",
    "    input_mask = batch[1]\n",
    "    masked_pred = prediction[:input_mask.sum().item(),:]\n",
    "    _ , words = torch.topk(masked_pred, 8, -1)\n",
    "    counter = 0\n",
    "    for word in words.squeeze():\n",
    "        counter += int(len(np.intersect1d(word.numpy(), category_vocab))>0)\n",
    "        intersect_time = time() - intersect_time_start\n",
    "        if counter > 0:\n",
    "            print('break')\n",
    "            return False\n",
    "            break\n",
    "    return True\n",
    "            \n",
    "def occurences(word, vocab = category_vocab):\n",
    "    return len(np.intersect1d(word.cpu().numpy(), vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [01:25,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8571428571428571\n",
      "number of elements retrieved 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [02:12,  1.17it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-0305e49e6332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mstart_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mmasked_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# #### Get negative set\n",
    "\n",
    "# from time import time\n",
    "# verified_negative = []\n",
    "# correct_label = 0\n",
    "# verbose = False\n",
    "# topk = 25\n",
    "# vocab = torch.tensor(category_vocab).to(device)\n",
    "# min_similar_words = 1\n",
    "# max_category_word = 0\n",
    "# num_cpus = 8\n",
    "# with torch.no_grad():\n",
    "#     for k, batch in tqdm(enumerate(dataloader)):\n",
    "#         start_time = time()\n",
    "#         input_ids, input_mask, label_id = batch\n",
    "#         predictions = model(input_ids.to(device),\n",
    "#                         pred_mode=\"mlm\",\n",
    "#                         token_type_ids=None, \n",
    "#                         attention_mask=input_mask.to(device))\n",
    "#         end_prediction_time = time()\n",
    "        \n",
    "        \n",
    "#     ########### GPU    \n",
    "# #         intersection, indices = intersect_tensor(torch.topk(predictions,topk,-1)[1],vocab, \n",
    "# #                                                 mask = input_mask.unsqueeze(2).repeat(1,1,topk).to(device))\n",
    "# #         counts_similar_word_per_word = indices.sum(-1) \n",
    "        \n",
    "# #         counts = (counts_similar_word_per_word>min_similar_words).sum(-1)\n",
    "# #         end_intersection_time = time()\n",
    "        \n",
    "# #         indices_count = torch.where(counts<=0)[0]\n",
    "# #         for j in indices_count:\n",
    "# #             i = j.item()\n",
    "\n",
    "#     ################## CPU ####################\"\"\n",
    "# #         counts = Parallel(n_jobs=num_cpus)(delayed(count_similar_words)(batch) for batch in zip(predictions.cpu(), input_mask))\n",
    "    \n",
    "    \n",
    "    \n",
    "#         for i, doc in enumerate(predictions.cpu()):\n",
    "#             start_loop = time()\n",
    "#             masked_pred = doc[:input_mask[i].sum().item(),:]\n",
    "#             _ , words = torch.topk(masked_pred, topk, -1)\n",
    "#             counter = 0\n",
    "#             topk_time = time()\n",
    "            \n",
    "# #             counts = Parallel(n_jobs=num_cpus)(delayed(occurences)(word) \n",
    "# #                                                    for word in words.squeeze())\n",
    "# #             counter += len(np.where(np.array(counts)>min_similar_words)[0])\n",
    "#             for word in words.squeeze():\n",
    "# #                 counter += int(len(intersect_tensor(word, vocab))>0)\n",
    "#                 counter += int(len(np.intersect1d(word.cpu().numpy(), category_vocab))>min_similar_words)\n",
    "#                 intersect_time = time() - intersect_time_start\n",
    "#                 if counter > max_category_word:\n",
    "#                     break\n",
    "\n",
    "# #             j = i.item()\n",
    "# #         for i in np.where(np.array(counts))[0]:\n",
    "\n",
    "#             if counter <= max_category_word:             \n",
    "#                 verified_negative.append(k*4+i)\n",
    "#                 if label_id[i] not in positive_label:\n",
    "#                     correct_label += 1 \n",
    "            \n",
    "#         end_counting_time = time()    \n",
    "#         if k%100 == 0:\n",
    "#             if len(verified_negative)>0:\n",
    "#                 print('accuracy :', correct_label/len(verified_negative))\n",
    "#                 print('number of elements retrieved', len(verified_negative))\n",
    "# #         if verbose:\n",
    "# #             print('Prediction time', end_prediction_time-start_time) \n",
    "# # #             print('bascule cpu', start_loop-end_prediction_time)\n",
    "# #             print('Intersection time', end_intersection_time-end_prediction_time)\n",
    "# # #             print('topk time', topk_time-start_loop)\n",
    "# #             print('counting time', end_counting_time-end_intersection_time)\n",
    "# #         del predictions\n",
    "# #         gc.collect()\n",
    "# #         torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as p\n",
    "\n",
    "# p.dump(verified_negative, open('verified_negative_sports.p','wb'))\n",
    "# p.dump(dataloader, open('dataloader_sports.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### TRAINING PART ###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DATASET CONSTRUCTION ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_verified_negative = p.load(open('verified_negative.p','rb'))\n",
    "new_dataloader = p.load(open('dataloader.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_data = torch.load('mcp_train.pt')\n",
    "label = torch.LongTensor([1]).repeat(len(mcp_data['labels']))\n",
    "mcp_data['labels'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_dataset = Subset(new_dataloader.dataset, new_verified_negative)\n",
    "positive_dataset = torch.utils.data.TensorDataset(mcp_data['input_ids'], mcp_data['attention_masks'], mcp_data['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.hstack((np.zeros(int(len(negative_dataset)), dtype=np.int32),\n",
    "                    np.ones(int(len(positive_dataset)), dtype=np.int32)))\n",
    "\n",
    "class_sample_count = np.array(\n",
    "    [len(np.where(target == t)[0]) for t in np.unique(target)])\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in target])\n",
    "\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weigth = samples_weight.double()\n",
    "target = torch.from_numpy(target).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.stack([negative_data[0][:200] for negative_data in negative_dataset] + \n",
    "            [positive_data[0][:200] for positive_data in positive_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.stack([negative_data[1][:200] for negative_data in negative_dataset] + \n",
    "            [positive_data[1][:200] for positive_data in positive_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(data,mask, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING LOOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing LOTClassModel: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing LOTClassModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LOTClassModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LOTClassModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias', 'dense.weight', 'dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 16/16 [00:05<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.41015625\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.390625\n",
      "tensor(0.7166, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.3828125\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.39453125\n",
      "tensor(0.6705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6785, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.37109375\n",
      "tensor(0.6506, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.349609375\n",
      "tensor(0.6073, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.416015625\n",
      "tensor(0.6605, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.4765625\n",
      "tensor(0.5990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5902, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.654296875\n",
      "tensor(0.5558, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.736328125\n",
      "tensor(0.5541, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.7890625\n",
      "tensor(0.5121, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.8515625\n",
      "tensor(0.4840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4897, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.92578125\n",
      "tensor(0.4963, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.91796875\n",
      "tensor(0.3918, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.953125\n",
      "tensor(0.4688, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9609375\n",
      "tensor(0.3814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3585, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.953125\n",
      "tensor(0.2797, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.966796875\n",
      "tensor(0.3243, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.95703125\n",
      "tensor(0.3700, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.962890625\n",
      "tensor(0.3145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3599, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.953125\n",
      "tensor(0.3279, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.955078125\n",
      "tensor(0.2930, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.970703125\n",
      "tensor(0.1995, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.970703125\n",
      "tensor(0.2089, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1774, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.95703125\n",
      "tensor(0.1930, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.97265625\n",
      "tensor(0.2282, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.958984375\n",
      "tensor(0.1713, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.958984375\n",
      "tensor(0.1886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1567, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9609375\n",
      "tensor(0.1194, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.978515625\n",
      "tensor(0.2339, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.966796875\n",
      "tensor(0.1345, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.95703125\n",
      "tensor(0.1123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1248, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.982421875\n",
      "tensor(0.2491, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.986328125\n",
      "tensor(0.1834, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9609375\n",
      "tensor(0.1234, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.958984375\n",
      "tensor(0.2068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1264, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.984375\n",
      "tensor(0.1303, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.970703125\n",
      "tensor(0.1651, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 9/16 [00:03<00:02,  2.72it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f0b3dcb1b78a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mavg_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maccum_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Average training loss: {avg_train_loss.mean().item()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-e2e7ced3c81f>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(number, test_batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mlogits_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mcorrect_pred\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_pred\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model = LOTClassModel.from_pretrained('bert-base-uncased',\n",
    "                                           output_attentions=False,\n",
    "                                           output_hidden_states=False,\n",
    "                                           num_labels=2).to(device)\n",
    "accum_steps = 8\n",
    "model.train()\n",
    "epochs = 1\n",
    "train_loss = nn.CrossEntropyLoss()\n",
    "total_steps = len(train_loader) * epochs / accum_steps\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.1*total_steps, num_training_steps=total_steps)\n",
    "losses_track = []\n",
    "try:\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        model.zero_grad()\n",
    "        for j, batch in enumerate(train_loader):\n",
    "            input_ids = batch[0].to(device)\n",
    "            input_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "\n",
    "\n",
    "            ### RANDOM MASKING\n",
    "            random_masking = random.choices(list(range(199)),k=batch_size)\n",
    "            for i, mask_pos in enumerate(random_masking):\n",
    "                input_ids[i,mask_pos+1] = tokenizer.get_vocab()[tokenizer.mask_token]\n",
    "            \n",
    "            ### PREDICTION\n",
    "            logits = model(input_ids, \n",
    "                           pred_mode=\"classification\",\n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=input_mask)\n",
    "            ### LOSS\n",
    "            logits_cls = logits[:,0]\n",
    "            loss = train_loss(logits_cls.view(-1, 2), labels.view(-1)) / accum_steps            \n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            if (j+1) % accum_steps == 0:\n",
    "                # Clip the norm of the gradients to 1.0.\n",
    "                print(loss*accum_steps)\n",
    "                losses_track.append(loss*accum_steps)\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.zero_grad()\n",
    "            if j % 10 == 0 :\n",
    "                test()\n",
    "        avg_train_loss = torch.tensor([total_train_loss / len(train_loader) * accum_steps]).to(device)\n",
    "        print(f\"Average training loss: {avg_train_loss.mean().item()}\")\n",
    "\n",
    "except RuntimeError as err:\n",
    "    print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as p\n",
    "# p.dump(verified_negative, open('verified_negative.p','wb'))\n",
    "# p.dump(dataloader, open('dataloader.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## TRAINING #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [20:03<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  227.732421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "227.732421875"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0')\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "k = random.sample(range(120000), k=1)[0]\n",
    "x, m = encode(docs[k])\n",
    "label = list_label[k]\n",
    "pred = model(x.to(device), attention_mask = m.to(device), pred_mode='classification')\n",
    "print(torch.argmax(pred[0,0,:]))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.971648"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "227.73*512/120000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0')\n",
      "2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top k = top 8 -> ~0.8 accuracy, 400 datapoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
